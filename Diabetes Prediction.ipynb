{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diabetes using Artificial Neural Network\n",
    "\n",
    "In this notebook we will learn how to predict whether a person will acquire diabetes in her lifetime given various body parameters using Neural Networks\n",
    "\n",
    "## Importing Dependencies\n",
    "1. [Numpy](https://www.numpy.org/): For matrix calculations\n",
    "2. [Pandas](https://pandas.pydata.org/): For reading csv file\n",
    "3. [Matplotlib](https://matplotlib.org/): For plotting data\n",
    "4. [Scikit-Learn](https://scikit-learn.org/): Splitting and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm_notebook\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "## for producing consistent results\n",
    "tf.set_random_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "Dataset contains following columns:\n",
    "1. Pregnancies: Number of times pregnant\n",
    "2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "4. SkinThickness: Triceps skin fold thickness (mm)\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "6. BMI: Body mass index (weight in kg/(height in m)^2)\n",
    "7. DiabetesPedigreeFunction: Diabetes pedigree function\n",
    "8. Age: Age (years)\n",
    "9. Outcome:  Class variable (0 or 1)\n",
    "\n",
    "More inofrmation about dataset can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset link\n",
    "DATA_LINK = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "## reading csv file present at url\n",
    "data = pd.read_csv(DATA_LINK, header = None)\n",
    "\n",
    "## first 10 rows\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting features\n",
    "X_data = np.array(data.iloc[:, 0:8])\n",
    "\n",
    "## normalizing dataset\n",
    "X_data -= np.mean(X_data, axis = 0)\n",
    "X_data /= np.std(X_data, axis = 0)\n",
    "\n",
    "## target\n",
    "y_data = np.array(data.iloc[:, 8])\n",
    "\n",
    "## the numpy array returned is of shape (n_examples,) but we need a 2-D array to feed to tensor\n",
    "y_data = np.expand_dims(y_data, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset\n",
    "For the purpose of training and testing, we split the dataset in ratio of 70% (training) and 30% (testing) <br/>\n",
    "For this purpose we use [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function of [scikit-learn](https://scikit-learn.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## placeholder for features\n",
    "X = tf.placeholder(tf.float32, [None, 8])\n",
    "\n",
    "## placeholder for output\n",
    "y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture\n",
    "In this problem we use a Dense Neural Network, with 2 hidden layers with 12 and 8 hidden units, respectively. <br/>\n",
    "For the first hidden layer, relu activation is used and for the second hidden unit, tanh activation is used.\n",
    "<img src = \"Images/nn.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weights for the model\n",
    "weights = {'W1': tf.Variable(np.random.randn(8, 12), dtype = tf.float32),\n",
    "           'b1': tf.Variable(np.random.randn(12), dtype = tf.float32),\n",
    "           'W2': tf.Variable(np.random.randn(12, 8), dtype = tf.float32),\n",
    "           'b2': tf.Variable(np.random.randn(8), dtype = tf.float32),\n",
    "           'W3': tf.Variable(np.random.randn(8, 1), dtype = tf.float32),\n",
    "           'b3': tf.Variable(np.random.randn(1), dtype = tf.float32)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateProbability(weights, X):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## first layer\n",
    "    layer_1 = tf.matmul(X, weights[\"W1\"]) + weights[\"b1\"]\n",
    "    ## relu activation\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    ## second layer\n",
    "    layer_2 = tf.matmul(layer_1, weights[\"W2\"]) + weights[\"b2\"]\n",
    "    ## tanh activation\n",
    "    layer_2 = tf.nn.tanh(layer_2)\n",
    "    \n",
    "    ## third layer\n",
    "    layer_3 = tf.matmul(layer_2,weights[\"W3\"]) + weights[\"b3\"]\n",
    "    return tf.sigmoid(layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, X, y):\n",
    "    predict_prob = generateProbability(weights, X)\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = predict_prob, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, X):\n",
    "    predict_proba = generateProbability(weights, X)\n",
    "    return tf.math.floor(2 * predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = loss(weights, X, y)\n",
    "pred = predict(weights, X)\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_cost_cache = []\n",
    "test_cost_cache = []\n",
    "train_acc_cache = []\n",
    "test_acc_cache = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ## initializing global variables\n",
    "    sess.run(init)\n",
    "    for num_iter in tqdm_notebook(range(250)):\n",
    "        \n",
    "        ## data fed through feed dictionary\n",
    "        ## returns the optimizer and current cost\n",
    "        _, train_cost, train_predictions = sess.run([optimizer, cost, pred], feed_dict = {X: X_train, y: y_train})\n",
    "        test_cost, test_predictions = sess.run([cost, pred], feed_dict = {X: X_test, y: y_test})\n",
    "        \n",
    "        \n",
    "        if num_iter % 10 == 0:\n",
    "            train_cost_cache.append(train_cost)\n",
    "            \n",
    "            print(\"Iteration: {}, Training Loss = {}\".format(num_iter, train_cost))\n",
    "            print(\"Training Accuracy = {}\".format(accuracy_score(train_predictions, y_train)))\n",
    "            \n",
    "            train_acc_cache.append(accuracy_score(train_predictions, y_train))\n",
    "            \n",
    "            test_cost_cache.append(test_cost)\n",
    "            \n",
    "            print(\"Test Loss = {}\".format(test_cost))\n",
    "            print(\"Test Accuracy = {}\".format(accuracy_score(test_predictions, y_test)))\n",
    "            test_acc_cache.append(accuracy_score(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_cost_cache)\n",
    "plt.ylabel('Training Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_acc_cache)\n",
    "plt.ylabel('Training Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(test_cost_cache)\n",
    "plt.ylabel('Test loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(test_acc_cache)\n",
    "plt.ylabel('Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"diabetes.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model(\"diabetes.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
